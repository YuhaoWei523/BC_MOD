import os
import pandas as pd
import requests
from bs4 import BeautifulSoup
import time
import tarfile
from tqdm import tqdm


class GEOMatrixDownloaderV2:
    def __init__(self, output_dir="./data"):
        self.output_dir = output_dir
        self.session = requests.Session()
        # æ¨¡æ‹Ÿæµè§ˆå™¨å¤´ï¼Œé˜²æ­¢è¢«æ‹’
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        os.makedirs(output_dir, exist_ok=True)

    def download_file(self, url, dest_path):
        """æµå¼ä¸‹è½½æ–‡ä»¶"""
        try:
            with self.session.get(url, stream=True, timeout=60) as r:
                if r.status_code == 404:
                    return False
                r.raise_for_status()
                total_size = int(r.headers.get('content-length', 0))

                with open(dest_path, 'wb') as f, tqdm(
                        desc=os.path.basename(dest_path),
                        total=total_size,
                        unit='iB',
                        unit_scale=True,
                        unit_divisor=1024,
                ) as bar:
                    for chunk in r.iter_content(chunk_size=8192):
                        f.write(chunk)
                        bar.update(len(chunk))
            return True
        except Exception as e:
            if os.path.exists(dest_path):
                os.remove(dest_path)
            return False

    def construct_ftp_url(self, gse_id):
        """
        ç­–ç•¥Aï¼šç›´æŽ¥æž„é€  FTP/HTTP è·¯å¾„ï¼ˆæœ€ç¨³å¥ï¼Œä¸éœ€è¦è§£æžç½‘é¡µï¼‰
        è§„å¾‹ï¼šhttps://ftp.ncbi.nlm.nih.gov/geo/series/GSEnnn/GSE12345/suppl/GSE12345_RAW.tar
        """
        # æå–æ•°å­—éƒ¨åˆ†
        num_part = gse_id.replace("GSE", "")
        # GEO çš„å­˜å‚¨æ¡¶é€»è¾‘ï¼šGSE161529 -> GSE161nnn
        if len(num_part) < 3:
            stub = "GSE" + num_part
        else:
            stub = "GSE" + num_part[:-3] + "nnn"

        base_url = f"https://ftp.ncbi.nlm.nih.gov/geo/series/{stub}/{gse_id}/suppl"

        # å°è¯•å‡ ç§å¸¸è§çš„æ–‡ä»¶åç»„åˆ
        candidates = [
            f"{base_url}/{gse_id}_RAW.tar",
            f"{base_url}/{gse_id}_RAW.tar.gz"
        ]
        return candidates

    def extract_tar(self, file_path, extract_path):
        try:
            print(f"  ðŸ“¦ è§£åŽ‹ä¸­: {file_path}")
            if file_path.endswith('.tar'):
                with tarfile.open(file_path, 'r:') as tar:
                    tar.extractall(path=extract_path)
            return True
        except Exception as e:
            print(f"  âŒ è§£åŽ‹é”™è¯¯: {e}")
            return False

    def process_gse(self, gse_id):
        # ä¿®æ­£è¾“å…¥å¯èƒ½å¸¦æœ‰çš„é‡å¤ GSE å‰ç¼€
        if gse_id.startswith("GSEGSE"):
            gse_id = gse_id.replace("GSEGSE", "GSE")

        print(f"\n{'=' * 60}")
        print(f"å¤„ç†æ•°æ®é›†: {gse_id}")

        gse_dir = os.path.join(self.output_dir, gse_id)
        os.makedirs(gse_dir, exist_ok=True)

        # --- ðŸ” æ›´æ–°åŽçš„æ£€æŸ¥é€»è¾‘: é€’å½’æŸ¥æ‰¾ .mtx.gz ---
        # åŽŸå› ï¼šè§£åŽ‹åŽæˆ–æ•´ç†åŽçš„æ–‡ä»¶é€šå¸¸åœ¨ GSMxxx å­æ–‡ä»¶å¤¹ä¸­ï¼Œos.listdir çœ‹ä¸åˆ°
        has_data = False
        for root, dirs, files in os.walk(gse_dir):
            if any(f.endswith('matrix.mtx.gz') or f.endswith('.mtx.gz') for f in files):
                has_data = True
                break

        if has_data:
            print("  âœ… æ£€æµ‹åˆ°å­ç›®å½•ä¸­å·²å­˜åœ¨ .mtx.gz æ–‡ä»¶ï¼Œè·³è¿‡ä¸‹è½½ã€‚")
            return 'skipped'
        # ------------------------------------------------

        # --- ç­–ç•¥ A: æš´åŠ›æž„é€ é“¾æŽ¥ (ä¼˜å…ˆå°è¯•) ---
        print("  ðŸ”„ å°è¯•ç›´æŽ¥æž„é€ ä¸‹è½½é“¾æŽ¥...")
        candidates = self.construct_ftp_url(gse_id)
        success = False

        for url in candidates:
            filename = url.split('/')[-1]
            save_path = os.path.join(gse_dir, filename)

            # é¢å¤–æ£€æŸ¥ï¼šå¦‚æžœ tar åŒ…å·²ç»å­˜åœ¨ä½†æ²¡è§£åŽ‹ï¼ˆå¯èƒ½æ˜¯ä¸Šæ¬¡ä¸­æ–­äº†ï¼‰
            if os.path.exists(save_path):
                print(f"  ðŸ“¦ å‘çŽ°å·²å­˜åœ¨çš„åŽ‹ç¼©åŒ…: {filename}ï¼Œå°è¯•ç›´æŽ¥è§£åŽ‹...")
                if self.extract_tar(save_path, gse_dir):
                    success = True
                    break
                else:
                    print("  âš ï¸ çŽ°æœ‰åŽ‹ç¼©åŒ…è§£åŽ‹å¤±è´¥ï¼ˆå¯èƒ½å·²æŸåï¼‰ï¼Œé‡æ–°ä¸‹è½½...")
                    os.remove(save_path)  # åˆ é™¤åæ–‡ä»¶

            print(f"  âž¡ï¸ å°è¯•ä¸‹è½½: {filename}")

            if self.download_file(url, save_path):
                print("  âœ… ä¸‹è½½æˆåŠŸï¼")
                self.extract_tar(save_path, gse_dir)
                success = True
                break

        if success:
            return 'success'

        # --- ç­–ç•¥ B: çˆ¬è™«è§£æž (å¤‡ç”¨) ---
        print("  âš ï¸ ç›´æŽ¥æž„é€ å¤±è´¥ï¼Œå°è¯•è§£æžç½‘é¡µ...")
        print(f"  âŒ {gse_id} è‡ªåŠ¨ä¸‹è½½å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨æ£€æŸ¥: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc={gse_id}")
        return 'failed'

    def run_from_csv(self, csv_path):
        df = pd.read_csv(csv_path)
        # ç¡®ä¿åŽ»é‡
        gse_ids = df['gse_id'].unique()
        print(f"å¾…å¤„ç†æ•°æ®é›†: {len(gse_ids)} ä¸ª")

        for gse_id in gse_ids:
            self.process_gse(gse_id)


if __name__ == "__main__":
    # ä½¿ç”¨ä¹‹å‰ç”Ÿæˆçš„ CSV
    csv_file = "./data/breast_cancer_scRNA_seq_GSE.csv"
    downloader = GEOMatrixDownloaderV2(output_dir="./data")
    if os.path.exists(csv_file):
        downloader.run_from_csv(csv_file)
    else:
        print("æœªæ‰¾åˆ° CSV æ–‡ä»¶")